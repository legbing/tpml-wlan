{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_TF_Optuna.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "554Zzp_EwJnH",
        "outputId": "764d24dd-db21-4e0c-97d5-182be1c9ccd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 19.1 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.39)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.9.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 13.1 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=07825e96fdeb868a4a6357b5b4b09e129d69f39d74cf7ee74837eb61a7182b87\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.1 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.6.0 optuna-2.10.1 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch as T\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision import transforms, utils\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#import optuna\n",
        "#from optuna.trial import TrialState\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "u4DSYZhIwEI5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full = pd.read_csv(\"full_dataset_with_int_map.csv\", index_col=None)\n",
        "X = df_full.iloc[:, 1:22]\n",
        "y = df_full.loc[:, \"throughput\"]"
      ],
      "metadata": {
        "id": "XwNJ1sz3o6ia"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('fin-train.csv',delimiter=',')#Enter the location of the preprocessed training data\n",
        "\n",
        "X = data.loc[:, ['wlan_code_index','node_type','x(m)','y(m)','primary_channel','min_channel_allowed',\n",
        "                       'max_channel_allowed','RSSI','SINR','average_airtime', 'average_interference']].values\n",
        "y = data.loc[:,\"throughput\"].values\n"
      ],
      "metadata": {
        "id": "7_1E6S8oy16y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if T.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2uyrVpxwTYf",
        "outputId": "7c543ed5-5872-4779-a7a6-8b576a2d5d7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRJxwsE9lvS6",
        "outputId": "79a1bbd1-63ee-43ad-e5da-ef8739273c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-04 07:43:46,714]\u001b[0m A new study created in memory with name: no-name-e5a859a2-0ce2-4521-a675-5f891294f00a\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:44:03,286]\u001b[0m Trial 0 finished with value: 0.9567144907760774 and parameters: {'n_units_l0': 949, 'n_units_l1': 447, 'n_units_l2': 704, 'n_units_l3': 329, 'learning_rate': 0.0008430508472070481}. Best is trial 0 with value: 0.9567144907760774.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:44:19,601]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_units_l0': 739, 'n_units_l1': 856, 'n_units_l2': 221, 'n_units_l3': 977, 'learning_rate': 0.030426921606847752}. Best is trial 0 with value: 0.9567144907760774.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:44:35,425]\u001b[0m Trial 2 finished with value: 0.9506593635252801 and parameters: {'n_units_l0': 832, 'n_units_l1': 60, 'n_units_l2': 361, 'n_units_l3': 488, 'learning_rate': 0.0021304377861830225}. Best is trial 0 with value: 0.9567144907760774.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:44:57,299]\u001b[0m Trial 3 finished with value: 0.9597191888446857 and parameters: {'n_units_l0': 630, 'n_units_l1': 46, 'n_units_l2': 372, 'n_units_l3': 924, 'learning_rate': 0.0064109158616299945}. Best is trial 3 with value: 0.9597191888446857.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:45:19,197]\u001b[0m Trial 4 finished with value: 0.9514113550225334 and parameters: {'n_units_l0': 879, 'n_units_l1': 512, 'n_units_l2': 999, 'n_units_l3': 247, 'learning_rate': 1.9362339449536156e-05}. Best is trial 3 with value: 0.9597191888446857.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:45:34,908]\u001b[0m Trial 5 finished with value: 0.9609625768597823 and parameters: {'n_units_l0': 508, 'n_units_l1': 151, 'n_units_l2': 548, 'n_units_l3': 859, 'learning_rate': 9.168098482443464e-05}. Best is trial 5 with value: 0.9609625768597823.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:45:51,424]\u001b[0m Trial 6 finished with value: 0.9599955614794221 and parameters: {'n_units_l0': 684, 'n_units_l1': 615, 'n_units_l2': 980, 'n_units_l3': 909, 'learning_rate': 0.0013057936983099155}. Best is trial 5 with value: 0.9609625768597823.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:46:13,800]\u001b[0m Trial 7 finished with value: 0.9520856160280928 and parameters: {'n_units_l0': 908, 'n_units_l1': 901, 'n_units_l2': 110, 'n_units_l3': 83, 'learning_rate': 0.05035172581996375}. Best is trial 5 with value: 0.9609625768597823.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:46:29,519]\u001b[0m Trial 8 finished with value: 0.9519740402528516 and parameters: {'n_units_l0': 547, 'n_units_l1': 851, 'n_units_l2': 504, 'n_units_l3': 309, 'learning_rate': 0.009263127523290983}. Best is trial 5 with value: 0.9609625768597823.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:46:44,721]\u001b[0m Trial 9 finished with value: 0.9175239291227151 and parameters: {'n_units_l0': 177, 'n_units_l1': 52, 'n_units_l2': 236, 'n_units_l3': 490, 'learning_rate': 1.820125920495604e-05}. Best is trial 5 with value: 0.9609625768597823.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:47:00,696]\u001b[0m Trial 10 finished with value: 0.9613985710617133 and parameters: {'n_units_l0': 300, 'n_units_l1': 306, 'n_units_l2': 722, 'n_units_l3': 717, 'learning_rate': 0.0001602200540849465}. Best is trial 10 with value: 0.9613985710617133.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:47:23,089]\u001b[0m Trial 11 finished with value: 0.9614021494375874 and parameters: {'n_units_l0': 304, 'n_units_l1': 317, 'n_units_l2': 690, 'n_units_l3': 727, 'learning_rate': 0.00014051842561939946}. Best is trial 11 with value: 0.9614021494375874.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:47:38,787]\u001b[0m Trial 12 finished with value: 0.9592151888574664 and parameters: {'n_units_l0': 249, 'n_units_l1': 292, 'n_units_l2': 799, 'n_units_l3': 716, 'learning_rate': 0.00017479089277042684}. Best is trial 11 with value: 0.9614021494375874.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:48:00,652]\u001b[0m Trial 13 finished with value: 0.9621427870273814 and parameters: {'n_units_l0': 330, 'n_units_l1': 327, 'n_units_l2': 742, 'n_units_l3': 674, 'learning_rate': 0.00018383474317478808}. Best is trial 13 with value: 0.9621427870273814.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:48:22,589]\u001b[0m Trial 14 finished with value: 0.9620916569762122 and parameters: {'n_units_l0': 395, 'n_units_l1': 352, 'n_units_l2': 845, 'n_units_l3': 682, 'learning_rate': 0.0003849032796416139}. Best is trial 13 with value: 0.9621427870273814.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:48:44,980]\u001b[0m Trial 15 finished with value: 0.9568246665365225 and parameters: {'n_units_l0': 385, 'n_units_l1': 629, 'n_units_l2': 857, 'n_units_l3': 628, 'learning_rate': 0.0005074106901074999}. Best is trial 13 with value: 0.9621427870273814.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:49:06,864]\u001b[0m Trial 16 finished with value: 0.9474764169099246 and parameters: {'n_units_l0': 42, 'n_units_l1': 412, 'n_units_l2': 854, 'n_units_l3': 587, 'learning_rate': 3.817825550329592e-05}. Best is trial 13 with value: 0.9621427870273814.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:49:22,534]\u001b[0m Trial 17 finished with value: 0.9613837555365592 and parameters: {'n_units_l0': 417, 'n_units_l1': 187, 'n_units_l2': 574, 'n_units_l3': 823, 'learning_rate': 0.0005823165761446573}. Best is trial 13 with value: 0.9621427870273814.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:49:38,291]\u001b[0m Trial 18 finished with value: 0.9577189949663049 and parameters: {'n_units_l0': 126, 'n_units_l1': 702, 'n_units_l2': 906, 'n_units_l3': 454, 'learning_rate': 5.318844450709182e-05}. Best is trial 13 with value: 0.9621427870273814.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:49:53,816]\u001b[0m Trial 19 finished with value: 0.9631248518618242 and parameters: {'n_units_l0': 445, 'n_units_l1': 387, 'n_units_l2': 618, 'n_units_l3': 618, 'learning_rate': 0.00034958236523293957}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:50:16,232]\u001b[0m Trial 20 finished with value: 0.9589941036432078 and parameters: {'n_units_l0': 538, 'n_units_l1': 194, 'n_units_l2': 624, 'n_units_l3': 410, 'learning_rate': 0.0033590928346117544}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:50:38,121]\u001b[0m Trial 21 finished with value: 0.9599926807295671 and parameters: {'n_units_l0': 406, 'n_units_l1': 375, 'n_units_l2': 772, 'n_units_l3': 607, 'learning_rate': 0.00033976141143030866}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:51:00,936]\u001b[0m Trial 22 finished with value: 0.9630745352421443 and parameters: {'n_units_l0': 469, 'n_units_l1': 495, 'n_units_l2': 499, 'n_units_l3': 793, 'learning_rate': 0.00022204669653063327}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:51:17,245]\u001b[0m Trial 23 finished with value: 0.9588078223385383 and parameters: {'n_units_l0': 453, 'n_units_l1': 493, 'n_units_l2': 455, 'n_units_l3': 800, 'learning_rate': 5.233246642141316e-05}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:51:33,554]\u001b[0m Trial 24 finished with value: 0.962486643147428 and parameters: {'n_units_l0': 619, 'n_units_l1': 596, 'n_units_l2': 615, 'n_units_l3': 553, 'learning_rate': 0.00024893120289876493}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:51:49,648]\u001b[0m Trial 25 finished with value: 0.95956656189052 and parameters: {'n_units_l0': 628, 'n_units_l1': 745, 'n_units_l2': 429, 'n_units_l3': 548, 'learning_rate': 0.0012664566157924672}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:52:12,034]\u001b[0m Trial 26 finished with value: 0.9541688501036466 and parameters: {'n_units_l0': 600, 'n_units_l1': 591, 'n_units_l2': 628, 'n_units_l3': 780, 'learning_rate': 0.0003160704860178835}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:52:28,431]\u001b[0m Trial 27 finished with value: 0.9454791281787893 and parameters: {'n_units_l0': 481, 'n_units_l1': 537, 'n_units_l2': 617, 'n_units_l3': 1009, 'learning_rate': 0.0037314776018738107}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:52:44,822]\u001b[0m Trial 28 finished with value: 0.9295858905610863 and parameters: {'n_units_l0': 765, 'n_units_l1': 726, 'n_units_l2': 303, 'n_units_l3': 406, 'learning_rate': 1.0022418303912403e-05}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:53:01,190]\u001b[0m Trial 29 finished with value: 0.957542616609724 and parameters: {'n_units_l0': 576, 'n_units_l1': 465, 'n_units_l2': 491, 'n_units_l3': 214, 'learning_rate': 8.765895512930709e-05}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:53:17,471]\u001b[0m Trial 30 finished with value: 0.9573752599994854 and parameters: {'n_units_l0': 1022, 'n_units_l1': 1009, 'n_units_l2': 398, 'n_units_l3': 547, 'learning_rate': 0.0008639678164372869}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:53:39,416]\u001b[0m Trial 31 finished with value: 0.958014775184357 and parameters: {'n_units_l0': 300, 'n_units_l1': 426, 'n_units_l2': 691, 'n_units_l3': 652, 'learning_rate': 0.00026632040959434543}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n",
            "\u001b[32m[I 2022-08-04 07:54:01,806]\u001b[0m Trial 32 finished with value: 0.9590425334522374 and parameters: {'n_units_l0': 356, 'n_units_l1': 247, 'n_units_l2': 743, 'n_units_l3': 740, 'learning_rate': 0.00010379215864877815}. Best is trial 19 with value: 0.9631248518618242.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 33\n",
            "Best trial:\n",
            "  Value: 0.9631248518618242\n",
            "  Params: \n",
            "    n_units_l0: 445\n",
            "    n_units_l1: 387\n",
            "    n_units_l2: 618\n",
            "    n_units_l3: 618\n",
            "    learning_rate: 0.00034958236523293957\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "\n",
        "import optuna\n",
        "import sklearn\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "N_TRAIN_EXAMPLES = 5550\n",
        "N_VALID_EXAMPLES = 1850\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 1\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Clear clutter from previous tf.keras session graphs.\n",
        "    clear_session()\n",
        "\n",
        "    sc = StandardScaler()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "    X_train_scale = sc.fit_transform(X_train)\n",
        "    X_test_scale = sc.transform(X_test)\n",
        "    \n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(0), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(1), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(2), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(3), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "\n",
        "    # We compile our model with a sampled learning rate.\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    model.compile(\n",
        "        loss=\"mean_squared_error\",\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        metrics=[\"mean_squared_error\",\"mean_absolute_error\"],\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train_scale,\n",
        "        y_train,\n",
        "        validation_data=(X_test_scale, y_test),\n",
        "        shuffle=True,\n",
        "        batch_size=BATCHSIZE,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    # Evaluate the model accuracy on the validation set.\n",
        "    pred_y = model.predict(X_test_scale)\n",
        "    r2 = sklearn.metrics.r2_score(pred_y, y_test)\n",
        "    return r2\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "\n",
        "import sklearn\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "WP1l-8e9JhvW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "\n",
        "import optuna\n",
        "import sklearn\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "N_TRAIN_EXAMPLES = 5550\n",
        "N_VALID_EXAMPLES = 1850\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 1\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Clear clutter from previous tf.keras session graphs.\n",
        "    clear_session()\n",
        "\n",
        "    sc = StandardScaler()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "    X_train_scale = sc.fit_transform(X_train)\n",
        "    X_test_scale = sc.transform(X_test)\n",
        "    \n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(0), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(1), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(2), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(trial.suggest_int(\"n_units_l{}\".format(3), 32, 1024), activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "\n",
        "    # We compile our model with a sampled learning rate.\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    model.compile(\n",
        "        loss=\"mean_squared_error\",\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        metrics=[\"mean_squared_error\",\"mean_absolute_error\"],\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train_scale,\n",
        "        y_train,\n",
        "        validation_data=(X_test_scale, y_test),\n",
        "        shuffle=True,\n",
        "        batch_size=BATCHSIZE,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    # Evaluate the model accuracy on the validation set.\n",
        "    pred_y = model.predict(X_test_scale)\n",
        "    r2 = sklearn.metrics.r2_score(pred_y, y_test)\n",
        "    return r2\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "Y2gHud1fwL6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE = 128\n",
        "CLASSES = 1\n",
        "EPOCHS = 30"
      ],
      "metadata": {
        "id": "mhmQ6QrGKLtG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "cDo7y6yFMqnV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)\n",
        "X_train_scale = sc.fit_transform(X_train)\n",
        "X_test_scale = sc.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(445, activation=\"relu\"))\n",
        "model.add(Dense(387, activation=\"relu\"))\n",
        "model.add(Dense(618, activation=\"relu\"))\n",
        "model.add(Dense(618, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# We compile our model with a sampled learning rate.\n",
        "learning_rate = 0.00034958236523293957\n",
        "model.compile(\n",
        "    loss=\"mean_squared_error\",\n",
        "    optimizer=Adam(learning_rate=learning_rate),\n",
        "    metrics=[\"mean_squared_error\",\"mean_absolute_error\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scale,\n",
        "    y_train,\n",
        "    validation_data=(X_test_scale, y_test),\n",
        "    shuffle=True,\n",
        "    batch_size=BATCHSIZE,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "# Evaluate the model accuracy on the validation set.\n",
        "pred_y = model.predict(X_test_scale)\n",
        "r2 = sklearn.metrics.r2_score(pred_y, y_test)\n",
        "print(r2, math.sqrt(sklearn.metrics.mean_squared_error(pred_y, y_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buST38L93AU9",
        "outputId": "227221db-3981-4b92-abf4-279bc90b5a8c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9484485749749986 5.415807504848353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kucUZP-uzDbb",
        "outputId": "620b5d25-5ed1-4ef7-f0f5-282219233828"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)\n",
        "X_train_scale = sc.fit_transform(X_train)\n",
        "X_test_scale = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "-oH--nWDb1D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(r2, math.sqrt(sklearn.metrics.mean_squared_error(pred_y, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO3850JFJald",
        "outputId": "a34e03a9-5aa1-480f-954c-59d9f198e8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9638129381515405 4.891489784603009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y_tr = model.predict(X_train_scale)\n",
        "print(r2, math.sqrt(sklearn.metrics.mean_squared_error(pred_y_tr, y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZwKa2dMtuO",
        "outputId": "ee834d4a-4c19-4230-e5e2-276d38ebca83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9638129381515405 4.229699006767452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y8jrbyndNoMM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}