{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7400 entries, 0 to 7399\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           7400 non-null   int64  \n",
      " 1   0                    7400 non-null   float64\n",
      " 2   1                    7400 non-null   float64\n",
      " 3   2                    7400 non-null   float64\n",
      " 4   3                    7400 non-null   float64\n",
      " 5   4                    7400 non-null   float64\n",
      " 6   5                    7400 non-null   float64\n",
      " 7   6                    7400 non-null   float64\n",
      " 8   7                    7400 non-null   float64\n",
      " 9   8                    7400 non-null   float64\n",
      " 10  9                    7400 non-null   float64\n",
      " 11  10                   7400 non-null   float64\n",
      " 12  11                   7400 non-null   float64\n",
      " 13  wlan_code_index      7400 non-null   int64  \n",
      " 14  x(m)                 7400 non-null   float64\n",
      " 15  y(m)                 7400 non-null   float64\n",
      " 16  primary_channel      7400 non-null   int64  \n",
      " 17  min_channel_allowed  7400 non-null   int64  \n",
      " 18  max_channel_allowed  7400 non-null   int64  \n",
      " 19  RSSI                 7400 non-null   float64\n",
      " 20  SINR                 7400 non-null   float64\n",
      " 21  average_airtime      7400 non-null   float64\n",
      " 22  throughput           7400 non-null   float64\n",
      "dtypes: float64(18), int64(5)\n",
      "memory usage: 1.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>wlan_code_index</th>\n",
       "      <th>x(m)</th>\n",
       "      <th>y(m)</th>\n",
       "      <th>primary_channel</th>\n",
       "      <th>min_channel_allowed</th>\n",
       "      <th>max_channel_allowed</th>\n",
       "      <th>RSSI</th>\n",
       "      <th>SINR</th>\n",
       "      <th>average_airtime</th>\n",
       "      <th>throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>-103.96</td>\n",
       "      <td>-119.98</td>\n",
       "      <td>-82.35</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-111.61</td>\n",
       "      <td>-122.95</td>\n",
       "      <td>-103.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-58.226667</td>\n",
       "      <td>29.620000</td>\n",
       "      <td>95.74500</td>\n",
       "      <td>111.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-82.35</td>\n",
       "      <td>-100.95</td>\n",
       "      <td>-91.84</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-105.59</td>\n",
       "      <td>-108.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-55.365000</td>\n",
       "      <td>30.275000</td>\n",
       "      <td>89.63500</td>\n",
       "      <td>111.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-100.95</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>-108.60</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>-88.83</td>\n",
       "      <td>-119.82</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-60.646111</td>\n",
       "      <td>21.308333</td>\n",
       "      <td>63.36250</td>\n",
       "      <td>77.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-119.98</td>\n",
       "      <td>-100.95</td>\n",
       "      <td>-82.35</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-125.96</td>\n",
       "      <td>-111.61</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>-133.97</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-54.633077</td>\n",
       "      <td>29.581538</td>\n",
       "      <td>38.85500</td>\n",
       "      <td>43.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>-88.83</td>\n",
       "      <td>-108.60</td>\n",
       "      <td>-122.95</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>-106.97</td>\n",
       "      <td>-119.98</td>\n",
       "      <td>-82.35</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-58.994444</td>\n",
       "      <td>25.089444</td>\n",
       "      <td>41.93500</td>\n",
       "      <td>79.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>7395</td>\n",
       "      <td>-88.83</td>\n",
       "      <td>-82.35</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-108.60</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>-103.96</td>\n",
       "      <td>-88.83</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-55.834286</td>\n",
       "      <td>11.962857</td>\n",
       "      <td>20.09125</td>\n",
       "      <td>46.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>7396</td>\n",
       "      <td>-105.59</td>\n",
       "      <td>-91.84</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>-91.84</td>\n",
       "      <td>-100.95</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-82.35</td>\n",
       "      <td>-105.59</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-39.920000</td>\n",
       "      <td>16.840000</td>\n",
       "      <td>35.25125</td>\n",
       "      <td>116.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>7397</td>\n",
       "      <td>-122.95</td>\n",
       "      <td>-108.60</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-82.35</td>\n",
       "      <td>-119.98</td>\n",
       "      <td>-106.97</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>-122.95</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-53.174286</td>\n",
       "      <td>22.284286</td>\n",
       "      <td>44.76000</td>\n",
       "      <td>84.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7398</th>\n",
       "      <td>7398</td>\n",
       "      <td>-100.95</td>\n",
       "      <td>-108.60</td>\n",
       "      <td>-122.83</td>\n",
       "      <td>-133.97</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-111.61</td>\n",
       "      <td>-125.96</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-50.328000</td>\n",
       "      <td>21.276000</td>\n",
       "      <td>57.23500</td>\n",
       "      <td>20.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7399</th>\n",
       "      <td>7399</td>\n",
       "      <td>-105.59</td>\n",
       "      <td>-103.96</td>\n",
       "      <td>-111.61</td>\n",
       "      <td>-119.82</td>\n",
       "      <td>-88.83</td>\n",
       "      <td>-85.36</td>\n",
       "      <td>-94.85</td>\n",
       "      <td>-108.60</td>\n",
       "      <td>-79.34</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-56.532222</td>\n",
       "      <td>18.102222</td>\n",
       "      <td>79.22000</td>\n",
       "      <td>195.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7400 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0              0  10000.00    -79.34   -103.96   -119.98    -82.35    -94.85   \n",
       "1              1    -79.34  10000.00    -82.35   -100.95    -91.84    -85.36   \n",
       "2              2   -100.95    -79.34  10000.00    -79.34   -108.60    -94.85   \n",
       "3              3   -119.98   -100.95    -82.35  10000.00   -125.96   -111.61   \n",
       "4              4    -79.34    -88.83   -108.60   -122.95  10000.00    -85.36   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "7395        7395    -88.83    -82.35    -94.85   -108.60    -79.34  10000.00   \n",
       "7396        7396   -105.59    -91.84    -85.36    -91.84   -100.95    -85.36   \n",
       "7397        7397   -122.95   -108.60    -94.85    -82.35   -119.98   -106.97   \n",
       "7398        7398   -100.95   -108.60   -122.83   -133.97    -79.34    -94.85   \n",
       "7399        7399   -105.59   -103.96   -111.61   -119.82    -88.83    -85.36   \n",
       "\n",
       "             6         7         8  ...  wlan_code_index  x(m)  y(m)  \\\n",
       "0      -111.61   -122.95   -103.96  ...                0  10.0  10.0   \n",
       "1       -94.85   -105.59   -108.60  ...                1  30.0  10.0   \n",
       "2       -85.36    -88.83   -119.82  ...                2  50.0  10.0   \n",
       "3       -94.85    -79.34   -133.97  ...                3  70.0  10.0   \n",
       "4      -106.97   -119.98    -82.35  ...                4  10.0  30.0   \n",
       "...        ...       ...       ...  ...              ...   ...   ...   \n",
       "7395    -85.36   -103.96    -88.83  ...                5  30.0  30.0   \n",
       "7396  10000.00    -82.35   -105.59  ...                6  50.0  30.0   \n",
       "7397    -85.36  10000.00   -122.95  ...                7  70.0  30.0   \n",
       "7398   -111.61   -125.96  10000.00  ...                8  10.0  50.0   \n",
       "7399    -94.85   -108.60    -79.34  ...                9  30.0  50.0   \n",
       "\n",
       "      primary_channel  min_channel_allowed  max_channel_allowed       RSSI  \\\n",
       "0                   4                    4                    5 -58.226667   \n",
       "1                   6                    6                    7 -55.365000   \n",
       "2                   0                    0                    3 -60.646111   \n",
       "3                   2                    2                    3 -54.633077   \n",
       "4                   0                    0                    3 -58.994444   \n",
       "...               ...                  ...                  ...        ...   \n",
       "7395                0                    0                    7 -55.834286   \n",
       "7396                0                    0                    7 -39.920000   \n",
       "7397                0                    0                    3 -53.174286   \n",
       "7398                4                    4                    5 -50.328000   \n",
       "7399                0                    0                    7 -56.532222   \n",
       "\n",
       "           SINR  average_airtime  throughput  \n",
       "0     29.620000         95.74500      111.77  \n",
       "1     30.275000         89.63500      111.11  \n",
       "2     21.308333         63.36250       77.72  \n",
       "3     29.581538         38.85500       43.05  \n",
       "4     25.089444         41.93500       79.87  \n",
       "...         ...              ...         ...  \n",
       "7395  11.962857         20.09125       46.16  \n",
       "7396  16.840000         35.25125      116.58  \n",
       "7397  22.284286         44.76000       84.17  \n",
       "7398  21.276000         57.23500       20.81  \n",
       "7399  18.102222         79.22000      195.46  \n",
       "\n",
       "[7400 rows x 23 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=pd.read_csv(\"C:\\\\Users\\\\shrey\\\\OneDrive\\\\Documents\\\\.PES\\\\PIL\\\\fin-dataset_2.csv\")\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\shrey\\\\OneDrive\\\\Documents\\\\.PES\\\\PIL\\\\full_dataset_with_int_map.csv\")\n",
    "df\n",
    "#df.drop(['node_code'],axis=1)\n",
    "df.head()\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.12.0+cu113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=df['throughput'].values #throughput \n",
    "\n",
    "\n",
    "#x=df[[ 'node_type', 'x(m)', 'y(m)',\n",
    "#       'primary_channel', 'min_channel_allowed', 'max_channel_allowed', 'RSSI',\n",
    "#       'SINR', 'average_airtime', 'average_interference',\n",
    "#       'wlan_code_index']].values\n",
    "x=df[['0','1','2','3','4', '5', '6', '7', '8', '9', '10',\n",
    "       '11', 'wlan_code_index', 'x(m)', 'y(m)', 'primary_channel',\n",
    "       'min_channel_allowed', 'max_channel_allowed', 'RSSI', 'SINR',\n",
    "       'average_airtime']].values  \n",
    "#x=df[[ 'wlan_code_index', 'x(m)', 'y(m)', 'primary_channel',\n",
    "#       'min_channel_allowed', 'max_channel_allowed', 'RSSI', 'SINR',\n",
    "#       'average_airtime']].values        \n",
    "      \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the dataframe into tensors for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5920, 21]) torch.Size([5920])\n",
      "torch.Size([1480, 21]) torch.Size([1480])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 65.6700,  89.7600, 117.3800,  ..., 141.2400,  12.9800, 131.4400])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.to_numpy()\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_train\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train).float())\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test).float())\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, n_features):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 256)\n",
    "    self.fc2 = nn.Linear(256, 256)\n",
    "    self.fc3=nn.Linear(256,256)\n",
    "    self.fc4 = nn.Linear(256, 256) # result is a single number so only one output\n",
    "    self.fc5=nn.Linear(256,256)\n",
    "    self.fc6=nn.Linear(256,256)\n",
    "    self.fc7=nn.Linear(256,256)\n",
    "    self.fc8=nn.Linear(256,256)\n",
    "    self.fc9=nn.Linear(256,256)\n",
    "    self.fc10=nn.Linear(256,1)\n",
    "    #self.fc4=nn.ReLU(1,4)\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    #return torch.sigmoid(self.fc3(x))\n",
    "    x=F.relu(self.fc3(x))\n",
    "    x=F.relu(self.fc4(x))\n",
    "    x=F.relu(self.fc5(x))\n",
    "    x=F.relu(self.fc6(x))\n",
    "    x=F.relu(self.fc7(x))\n",
    "    x=F.relu(self.fc8(x))\n",
    "    x=F.relu(self.fc9(x))\n",
    "    return self.fc10(x)\n",
    "\n",
    "    #return (x)\n",
    "# an instance\n",
    "net = Net(X_train.shape[1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![the NN](\"NN1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running it locally on gpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001) # lr is taken to be a small value for trial purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0559e+02, -1.0396e+02, -1.0559e+02,  ..., -5.4370e+01,\n",
      "          1.4528e+01,  1.9985e+01],\n",
      "        [-8.2350e+01, -9.6980e+01,  1.0000e+04,  ..., -5.3907e+01,\n",
      "          2.3477e+01,  3.8877e+01],\n",
      "        [-8.8200e+01,  1.0000e+04, -9.2780e+01,  ..., -5.6423e+01,\n",
      "          2.1201e+01,  5.7935e+01],\n",
      "        ...,\n",
      "        [-1.0302e+02, -9.3680e+01, -9.2780e+01,  ..., -5.7992e+01,\n",
      "          1.8361e+01,  2.8885e+01],\n",
      "        [-8.2350e+01, -9.6980e+01,  1.0000e+04,  ..., -5.1421e+01,\n",
      "          3.0713e+01,  4.7320e+01],\n",
      "        [-9.0270e+01, -7.8160e+01, -8.7260e+01,  ..., -6.1200e+01,\n",
      "          1.3876e+01,  9.3225e+00]]) tensor([ 56.6000,  84.3300, 194.7600,  ...,  36.1000,  65.5300,  15.2800]) tensor([[-1.0300e+02, -9.0670e+01, -9.1840e+01,  ..., -5.2751e+01,\n",
      "          2.6772e+01,  4.7490e+01],\n",
      "        [ 1.0000e+04, -9.6690e+01, -8.5360e+01,  ..., -5.3217e+01,\n",
      "          2.5479e+01,  7.8850e+01],\n",
      "        [-1.0095e+02, -7.9340e+01,  1.0000e+04,  ..., -5.4286e+01,\n",
      "          2.9534e+01,  8.5220e+01],\n",
      "        ...,\n",
      "        [-1.1982e+02, -1.0860e+02, -1.0396e+02,  ..., -6.0038e+01,\n",
      "          1.7654e+01,  5.9969e+01],\n",
      "        [-1.2596e+02, -1.0559e+02, -9.1840e+01,  ..., -5.9824e+01,\n",
      "          2.3041e+01,  7.0800e+00],\n",
      "        [-7.9430e+01, -7.0580e+01, -7.9430e+01,  ..., -5.4637e+01,\n",
      "          3.1880e+01,  8.9270e+01]]) tensor([ 65.6700,  89.7600, 117.3800,  ..., 141.2400,  12.9800, 131.4400])\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=torch.device(\"cpu\")\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "net = net.to(device)\n",
    "criterion = criterion.to(device)\n",
    "print(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calculate_accuracy(y_true, y_pred):\n",
    "#  predicted = y_pred#.ge(.5).view(-1)\n",
    "#  return (y_true == predicted).sum().float() / len(y_true)\n",
    "#  #correct=0 #test\n",
    "#  #for i in range(len(y_true)):\n",
    "#  #              correct += (((abs(y_pred[i] - y_true[i])/y_true[i]) * 100) < 10).type(torch.float).item()\n",
    "#  #return correct\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train set - loss: 10290.11, accuracy: -2.547\n",
      "\n",
      "\n",
      "epoch 100\n",
      "Train set - loss: 2604.162, accuracy: 0.102\n",
      "\n",
      "\n",
      "epoch 200\n",
      "Train set - loss: 2513.213, accuracy: 0.134\n",
      "\n",
      "\n",
      "epoch 300\n",
      "Train set - loss: 1981.5, accuracy: 0.317\n",
      "\n",
      "\n",
      "epoch 400\n",
      "Train set - loss: 1283.901, accuracy: 0.557\n",
      "\n",
      "\n",
      "epoch 500\n",
      "Train set - loss: 1185.001, accuracy: 0.591\n",
      "\n",
      "\n",
      "epoch 600\n",
      "Train set - loss: 1092.449, accuracy: 0.623\n",
      "\n",
      "\n",
      "epoch 700\n",
      "Train set - loss: 1610.617, accuracy: 0.445\n",
      "\n",
      "\n",
      "epoch 800\n",
      "Train set - loss: 957.742, accuracy: 0.67\n",
      "\n",
      "\n",
      "epoch 900\n",
      "Train set - loss: 937.395, accuracy: 0.677\n",
      "\n",
      "\n",
      "epoch 1000\n",
      "Train set - loss: 862.196, accuracy: 0.703\n",
      "\n",
      "\n",
      "epoch 1100\n",
      "Train set - loss: 918.258, accuracy: 0.683\n",
      "\n",
      "\n",
      "epoch 1200\n",
      "Train set - loss: 798.433, accuracy: 0.725\n",
      "\n",
      "\n",
      "epoch 1300\n",
      "Train set - loss: 767.695, accuracy: 0.735\n",
      "\n",
      "\n",
      "epoch 1400\n",
      "Train set - loss: 767.661, accuracy: 0.735\n",
      "\n",
      "\n",
      "epoch 1500\n",
      "Train set - loss: 853.999, accuracy: 0.706\n",
      "\n",
      "\n",
      "epoch 1600\n",
      "Train set - loss: 851.361, accuracy: 0.707\n",
      "\n",
      "\n",
      "epoch 1700\n",
      "Train set - loss: 708.979, accuracy: 0.756\n",
      "\n",
      "\n",
      "epoch 1800\n",
      "Train set - loss: 700.258, accuracy: 0.759\n",
      "\n",
      "\n",
      "epoch 1900\n",
      "Train set - loss: 720.823, accuracy: 0.752\n",
      "\n",
      "\n",
      "epoch 2000\n",
      "Train set - loss: 791.302, accuracy: 0.727\n",
      "\n",
      "\n",
      "epoch 2100\n",
      "Train set - loss: 745.994, accuracy: 0.743\n",
      "\n",
      "\n",
      "epoch 2200\n",
      "Train set - loss: 681.202, accuracy: 0.765\n",
      "\n",
      "\n",
      "epoch 2300\n",
      "Train set - loss: 666.35, accuracy: 0.77\n",
      "\n",
      "\n",
      "epoch 2400\n",
      "Train set - loss: 664.83, accuracy: 0.771\n",
      "\n",
      "\n",
      "epoch 2500\n",
      "Train set - loss: 650.26, accuracy: 0.776\n",
      "\n",
      "\n",
      "epoch 2600\n",
      "Train set - loss: 659.101, accuracy: 0.773\n",
      "\n",
      "\n",
      "epoch 2700\n",
      "Train set - loss: 579.433, accuracy: 0.8\n",
      "\n",
      "\n",
      "epoch 2800\n",
      "Train set - loss: 638.223, accuracy: 0.78\n",
      "\n",
      "\n",
      "epoch 2900\n",
      "Train set - loss: 610.044, accuracy: 0.79\n",
      "\n",
      "\n",
      "epoch 3000\n",
      "Train set - loss: 609.353, accuracy: 0.79\n",
      "\n",
      "\n",
      "epoch 3100\n",
      "Train set - loss: 543.784, accuracy: 0.813\n",
      "\n",
      "\n",
      "epoch 3200\n",
      "Train set - loss: 532.264, accuracy: 0.817\n",
      "\n",
      "\n",
      "epoch 3300\n",
      "Train set - loss: 644.852, accuracy: 0.778\n",
      "\n",
      "\n",
      "epoch 3400\n",
      "Train set - loss: 553.686, accuracy: 0.809\n",
      "\n",
      "\n",
      "epoch 3500\n",
      "Train set - loss: 502.97, accuracy: 0.827\n",
      "\n",
      "\n",
      "epoch 3600\n",
      "Train set - loss: 513.987, accuracy: 0.823\n",
      "\n",
      "\n",
      "epoch 3700\n",
      "Train set - loss: 505.926, accuracy: 0.826\n",
      "\n",
      "\n",
      "epoch 3800\n",
      "Train set - loss: 522.277, accuracy: 0.82\n",
      "\n",
      "\n",
      "epoch 3900\n",
      "Train set - loss: 608.703, accuracy: 0.79\n",
      "\n",
      "\n",
      "epoch 4000\n",
      "Train set - loss: 523.326, accuracy: 0.82\n",
      "\n",
      "\n",
      "epoch 4100\n",
      "Train set - loss: 450.976, accuracy: 0.845\n",
      "\n",
      "\n",
      "epoch 4200\n",
      "Train set - loss: 599.069, accuracy: 0.793\n",
      "\n",
      "\n",
      "epoch 4300\n",
      "Train set - loss: 730.075, accuracy: 0.748\n",
      "\n",
      "\n",
      "epoch 4400\n",
      "Train set - loss: 533.93, accuracy: 0.816\n",
      "\n",
      "\n",
      "epoch 4500\n",
      "Train set - loss: 1005.419, accuracy: 0.653\n",
      "\n",
      "\n",
      "epoch 4600\n",
      "Train set - loss: 452.527, accuracy: 0.844\n",
      "\n",
      "\n",
      "epoch 4700\n",
      "Train set - loss: 455.906, accuracy: 0.843\n",
      "\n",
      "\n",
      "epoch 4800\n",
      "Train set - loss: 486.91, accuracy: 0.832\n",
      "\n",
      "\n",
      "epoch 4900\n",
      "Train set - loss: 490.302, accuracy: 0.831\n",
      "\n",
      "\n",
      "epoch 5000\n",
      "Train set - loss: 497.561, accuracy: 0.828\n",
      "\n",
      "\n",
      "epoch 5100\n",
      "Train set - loss: 573.639, accuracy: 0.802\n",
      "\n",
      "\n",
      "epoch 5200\n",
      "Train set - loss: 409.125, accuracy: 0.859\n",
      "\n",
      "\n",
      "epoch 5300\n",
      "Train set - loss: 536.861, accuracy: 0.815\n",
      "\n",
      "\n",
      "epoch 5400\n",
      "Train set - loss: 470.728, accuracy: 0.838\n",
      "\n",
      "\n",
      "epoch 5500\n",
      "Train set - loss: 466.774, accuracy: 0.839\n",
      "\n",
      "\n",
      "epoch 5600\n",
      "Train set - loss: 449.249, accuracy: 0.845\n",
      "\n",
      "\n",
      "epoch 5700\n",
      "Train set - loss: 454.68, accuracy: 0.843\n",
      "\n",
      "\n",
      "epoch 5800\n",
      "Train set - loss: 389.575, accuracy: 0.866\n",
      "\n",
      "\n",
      "epoch 5900\n",
      "Train set - loss: 394.629, accuracy: 0.864\n",
      "\n",
      "\n",
      "epoch 6000\n",
      "Train set - loss: 441.875, accuracy: 0.848\n",
      "\n",
      "\n",
      "epoch 6100\n",
      "Train set - loss: 548.884, accuracy: 0.811\n",
      "\n",
      "\n",
      "epoch 6200\n",
      "Train set - loss: 519.567, accuracy: 0.821\n",
      "\n",
      "\n",
      "epoch 6300\n",
      "Train set - loss: 499.505, accuracy: 0.828\n",
      "\n",
      "\n",
      "epoch 6400\n",
      "Train set - loss: 418.623, accuracy: 0.856\n",
      "\n",
      "\n",
      "epoch 6500\n",
      "Train set - loss: 419.969, accuracy: 0.855\n",
      "\n",
      "\n",
      "epoch 6600\n",
      "Train set - loss: 388.491, accuracy: 0.866\n",
      "\n",
      "\n",
      "epoch 6700\n",
      "Train set - loss: 439.824, accuracy: 0.848\n",
      "\n",
      "\n",
      "epoch 6800\n",
      "Train set - loss: 417.658, accuracy: 0.856\n",
      "\n",
      "\n",
      "epoch 6900\n",
      "Train set - loss: 489.155, accuracy: 0.831\n",
      "\n",
      "\n",
      "epoch 7000\n",
      "Train set - loss: 398.858, accuracy: 0.863\n",
      "\n",
      "\n",
      "epoch 7100\n",
      "Train set - loss: 418.079, accuracy: 0.856\n",
      "\n",
      "\n",
      "epoch 7200\n",
      "Train set - loss: 435.527, accuracy: 0.85\n",
      "\n",
      "\n",
      "epoch 7300\n",
      "Train set - loss: 403.177, accuracy: 0.861\n",
      "\n",
      "\n",
      "epoch 7400\n",
      "Train set - loss: 389.582, accuracy: 0.866\n",
      "\n",
      "\n",
      "epoch 7500\n",
      "Train set - loss: 408.142, accuracy: 0.859\n",
      "\n",
      "\n",
      "epoch 7600\n",
      "Train set - loss: 374.673, accuracy: 0.871\n",
      "\n",
      "\n",
      "epoch 7700\n",
      "Train set - loss: 379.295, accuracy: 0.869\n",
      "\n",
      "\n",
      "epoch 7800\n",
      "Train set - loss: 400.017, accuracy: 0.862\n",
      "\n",
      "\n",
      "epoch 7900\n",
      "Train set - loss: 436.286, accuracy: 0.85\n",
      "\n",
      "\n",
      "epoch 8000\n",
      "Train set - loss: 423.464, accuracy: 0.854\n",
      "\n",
      "\n",
      "epoch 8100\n",
      "Train set - loss: 412.499, accuracy: 0.858\n",
      "\n",
      "\n",
      "epoch 8200\n",
      "Train set - loss: 311.609, accuracy: 0.893\n",
      "\n",
      "\n",
      "epoch 8300\n",
      "Train set - loss: 451.943, accuracy: 0.844\n",
      "\n",
      "\n",
      "epoch 8400\n",
      "Train set - loss: 370.575, accuracy: 0.872\n",
      "\n",
      "\n",
      "epoch 8500\n",
      "Train set - loss: 317.706, accuracy: 0.89\n",
      "\n",
      "\n",
      "epoch 8600\n",
      "Train set - loss: 298.665, accuracy: 0.897\n",
      "\n",
      "\n",
      "epoch 8700\n",
      "Train set - loss: 292.856, accuracy: 0.899\n",
      "\n",
      "\n",
      "epoch 8800\n",
      "Train set - loss: 361.836, accuracy: 0.875\n",
      "\n",
      "\n",
      "epoch 8900\n",
      "Train set - loss: 351.92, accuracy: 0.879\n",
      "\n",
      "\n",
      "epoch 9000\n",
      "Train set - loss: 311.348, accuracy: 0.893\n",
      "\n",
      "\n",
      "epoch 9100\n",
      "Train set - loss: 312.98, accuracy: 0.892\n",
      "\n",
      "\n",
      "epoch 9200\n",
      "Train set - loss: 455.009, accuracy: 0.843\n",
      "\n",
      "\n",
      "epoch 9300\n",
      "Train set - loss: 542.227, accuracy: 0.813\n",
      "\n",
      "\n",
      "epoch 9400\n",
      "Train set - loss: 360.506, accuracy: 0.876\n",
      "\n",
      "\n",
      "epoch 9500\n",
      "Train set - loss: 255.632, accuracy: 0.912\n",
      "\n",
      "\n",
      "epoch 9600\n",
      "Train set - loss: 312.314, accuracy: 0.892\n",
      "\n",
      "\n",
      "epoch 9700\n",
      "Train set - loss: 306.238, accuracy: 0.894\n",
      "\n",
      "\n",
      "epoch 9800\n",
      "Train set - loss: 275.541, accuracy: 0.905\n",
      "\n",
      "\n",
      "epoch 9900\n",
      "Train set - loss: 287.725, accuracy: 0.901\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define a new accuracy function based on r2\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#def accuracy_r2(y_true, y_pred):\n",
    "#  y_true=y_true.numpy()\n",
    "#  y_pred=y_pred.numpy()\n",
    "#  y_true=y_true.reshape(-1)\n",
    "#  y_pred=y_pred.reshape(-1)\n",
    "#  r2=r2_score(y_true,y_pred)\n",
    "#  return r2\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "iteration_list=[]\n",
    "loss_list=[] # to be updated\n",
    "accuracy_list=[]\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#X_train = X_train.to(device)\n",
    "#y_train = y_train.to(device)\n",
    "#X_test = X_test.to(device)\n",
    "#y_test = y_test.to(device)\n",
    "#net = net.to(device)\n",
    "#criterion = criterion.to(device)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    \n",
    "    \n",
    "    y_pred = net(X_train)\n",
    "\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    iteration_list.append(epoch)\n",
    "    loss_list.append(round_tensor(train_loss))\n",
    "    #accuracy_list.append(round_tensor(accuracy_r2(y_train, y_pred)))\n",
    "    #append r2 score into accuracy list\n",
    "    accuracy_list.append(round_tensor(r2_score(y_train.detach(), y_pred.detach())))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "      total=0\n",
    "      \n",
    "      train_acc = r2_score(y_train.detach(), y_pred.detach())\n",
    "      \n",
    "\n",
    "      print(\n",
    "f'''epoch {epoch}\n",
    "Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "\n",
    "''')\n",
    "      #print(f\"{y_test_pred}, {y_test}\")  Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  set - loss: 493.172, accuracy:0.847 MSE: 493.172\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "      y_test_pred = net(X_test)\n",
    "      y_test_pred = torch.squeeze(y_test_pred)\n",
    "      test_loss = criterion(y_test_pred, y_test)\n",
    "      test_acc = r2_score(y_test.detach(), y_test_pred.detach())\n",
    "      print(f\"Test  set - loss: {round_tensor(test_loss)}, accuracy:{round_tensor(test_acc)} MSE: {round_tensor(test_loss)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use this to see the loss graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iteration_list, loss_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the accuracy graph\n",
    "plt.plot(iteration_list, accuracy_list)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
